{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636\n",
      "7917\n",
      "675\n",
      "38581\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import urllib\n",
    "from lxml import html\n",
    "\n",
    "#A list to store URLs that lead to images\n",
    "#dtexts=[]\n",
    "dimages=[]\n",
    "\n",
    "#The idea is to check the extension part of each of the URLs to tell whether it is an image or a video. Hence, lists containing\n",
    "#such extension parts are needed here. These lists may not be perfect in the future if we have new formats for images and videos.\n",
    "#However, I think it is good enough to categorize the URLs for now.\n",
    "imgend=['ani','bmp','cal','fax','gif','img','jbg','jpe','jpeg','jpg','mac','pbm','pcd','pcx','pct','pgm','png','ppm','psd','ras','tga','tiff','wmf']\n",
    "mpend=['3gp','3g2','asf','avi','f4v','ismv','mp4','mkv','mov','m4v','mpeg','wmv','aac','amr','flac','m4a','midi','mka','mp3','ogg','qcp','spmid','wav','wma']\n",
    "\n",
    "images=0\n",
    "mp=0\n",
    "ip_address=0\n",
    "texts=0\n",
    "\n",
    "#This function is used to detect the urls with IP address as the domain (numeric parsed host)\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "#The process of generally categorizing the URLs into images, videos, IP addresses and texts starts here\n",
    "with open('processed_httphost2.csv') as csvfile:\n",
    "    reader=csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        checkend=(row['HttpUri1']+row['HttpUri2']+row['HttpUri3']+row['HttpUri4']+row['HttpUri5']).split('.')\n",
    "        if checkend[len(checkend)-1] in imgend:\n",
    "            dimages.append('http://'+row['HttpHost'] +row['HttpUri1']+row['HttpUri2']+row['HttpUri3']+row['HttpUri4']+row['HttpUri5'])\n",
    "            images=images+1\n",
    "        elif checkend[len(checkend)-1] in mpend:\n",
    "            mp=mp+1\n",
    "        elif is_number(row['HttpHostParsed'])==True:\n",
    "            ip_address=ip_address+1\n",
    "        else:\n",
    "            texts=texts+1\n",
    "            \n",
    "#This is just to see the amount of each of IP, images, videos and texts in the dataset\n",
    "print ip_address\n",
    "print images\n",
    "print mp\n",
    "print texts\n",
    "\n",
    "#Print out a csv file containing the images for image-based scraping using API. Text-based scraping will be done for\n",
    "#domains, not for the URLs specifically so having another csv file containing the text URLs is not necessary\n",
    "with open('imageurls.csv','w') as csvfile:\n",
    "    a=csv.writer(csvfile)\n",
    "    a.writerow('image_urls')\n",
    "    for i in range(0,len(dimages)):\n",
    "        a.writerow(dimages[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
